{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import pandas as pd\n",
    "import scipy.ndimage as sp\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "import scipy.stats as stats\n",
    "\n",
    "from skimage import io, exposure, data\n",
    "from skimage import feature\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "#----------MINFLUX tracks NP array to Pandas-----------------\n",
    "\n",
    "pd.set_option('display.float_format', '{:.20f}'.format)\n",
    "\n",
    "\n",
    "#import numpy raw data\n",
    "\n",
    "directory = '...'\n",
    "minflux = np.load('directory.npy')\n",
    "minf = pd.DataFrame({'track_id': minflux['tid'], 'time' : minflux['tim']})\n",
    "\n",
    "pos = pd.DataFrame((minflux['itr']['loc'][:,3]), columns = ['X','Y','Z'])\n",
    "\n",
    "\n",
    "min_data = pd.concat([minf, pos], axis=1)\n",
    "min_data_s = min_data.sort_values(by=['track_id', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "#-----------coordinate conversion- Lengths and offsets---------------\n",
    "#Length and offset are copied from metadata\n",
    "\n",
    "\n",
    "L = [1.4399999599845614e-05, 1.739999970595818e-05, 1.0, 1.0]\n",
    "O = [-2.5516666482872097e-05, -2.6513332159083802e-05, -0.5, -0.5]\n",
    "\n",
    "\n",
    "\n",
    "Lengths = [i * 1e6 for i in L]\n",
    "Offsets = [i * 1e6 for i in O]\n",
    "min_data_s.X = (min_data_s.X*1e6)-Offsets[0]\n",
    "min_data_s.Y = (min_data_s.Y*1e6)-Offsets[1]\n",
    "\n",
    "\n",
    "param = pd.DataFrame({'L': [L], 'O':[O], 'filename':min_filename})\n",
    "param = param.T\n",
    "#save track data in csv format\n",
    "min_data_s.to_csv('.../spots.csv')\n",
    "#save parameter file in csv format\n",
    "param.to_csv('.../params.csv')\n",
    "\n",
    "\n",
    "#--------import LD image----------------\n",
    "#pre and post tracking confocal images are exported and combined in a maximum intensity projection\n",
    "\n",
    "cmap3 = LinearSegmentedColormap.from_list('mycmap', ['white', 'darkgreen'])\n",
    "min_LDs = '/Volumes/PRO-G40/Arda/Arda/' + min_filename + '/LDs.tif'\n",
    "\n",
    "IMAGE = io.imread(min_LDs)\n",
    "pre = IMAGE[0]\n",
    "post = IMAGE[1]\n",
    "MIP= np.max(IMAGE, axis=0)\n",
    "image_minmax_scaled = exposure.rescale_intensity(MIP)\n",
    "percentiles = np.percentile(image_minmax_scaled, (70, 99.8))\n",
    "scaled = exposure.rescale_intensity(MIP,\n",
    "                                    in_range=tuple(percentiles))\n",
    "pre_LDs = exposure.rescale_intensity(pre,\n",
    "                                    in_range=tuple(percentiles))\n",
    "post_LDs = exposure.rescale_intensity(post,\n",
    "                                    in_range=tuple(percentiles))\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(scaled, cmap=cmap3, extent=[0,Lengths[0],Lengths[1],0])\n",
    "plt.xlabel('X (µm)')\n",
    "plt.ylabel('Y (µm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display all tracks\n",
    "\n",
    "plt.imshow(scaled, cmap=cmap3, extent=[0,Lengths[0],Lengths[1],0])\n",
    "sns.scatterplot(data= min_data_s, x = min_data_s.X, y = min_data_s.Y, hue = 'track_id', s = 0.01, alpha = 0.85,  \n",
    "                legend = False, palette = \"Set2\", edgecolor=None)\n",
    "sns.lineplot(data= min_data_s, x = min_data_s.X, y = min_data_s.Y, lw = 0.05, sort = False, estimator = None, \n",
    "             hue = 'track_id', palette = 'Set2', legend = False, alpha = 0.6)\n",
    "\n",
    "plt.xlim(0,Lengths[0])\n",
    "plt.ylim(0, Lengths[1])\n",
    "\n",
    "plt.xlabel ('X position (µm)')\n",
    "plt.ylabel ('Y position (µm)')\n",
    "#plt.axis('scaled')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829df46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def42d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----masking for lipid droplets and classifying tracks based on subcellular location-------\n",
    "\n",
    "import cv2\n",
    "from skimage import measure\n",
    "\n",
    "threshold_value = 150\n",
    "\n",
    "coor = pd.DataFrame({'track_id': min_data_s.track_id, 'X': min_data_s.X*20, 'Y': min_data_s.Y*20, 'time':min_data_s.time}, columns=['track_id','X', 'Y', 'time'])      \n",
    "\n",
    "def isolate_puncta(input_image_path, output_mask_path, output_expanded_path, output_coordinates_path, threshold_value):\n",
    "    # Load the image\n",
    "    image = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply a threshold to separate puncta from the background\n",
    "    _, binary_mask = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Label connected components in the binary mask\n",
    "    labeled_mask, num_labels = measure.label(binary_mask, connectivity=2, return_num=True)\n",
    "\n",
    "    # Get the properties of each labeled region (e.g., area, centroid)\n",
    "    region_properties = measure.regionprops(labeled_mask)\n",
    "\n",
    "    # Create a blank image to draw isolated puncta \n",
    "    isolated_puncta = np.zeros_like(image)\n",
    "\n",
    "    # Collect pixel coordinates of isolated puncta\n",
    "    coordinates = []\n",
    "\n",
    "    # Iterate through labeled regions and isolate puncta\n",
    "    for region in region_properties:\n",
    "        if region.area > 5:  # Adjust the area threshold as needed\n",
    "            # Draw the isolated punctum on the blank image\n",
    "            isolated_puncta[labeled_mask == region.label] = 255\n",
    "\n",
    "            # Collect pixel coordinates of the isolated puncta\n",
    "            coordinates.extend(region.coords.tolist())\n",
    "\n",
    "    # Expand the isolated mask by 3 pixels\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    expanded_mask = cv2.dilate(isolated_puncta, kernel, iterations=1)\n",
    "    \n",
    "    \n",
    "    # Save the binary mask, isolated puncta, and pixel coordinates\n",
    "    cv2.imwrite(output_mask_path, binary_mask)\n",
    "    cv2.imwrite(output_isolated_path, isolated_puncta)\n",
    "    cv2.imwrite(output_expanded_path, expanded_mask)\n",
    "    \n",
    "    # Create a DataFrame from the pixel coordinates\n",
    "    df_coordinates = pd.DataFrame(coordinates, columns=[\"Y\", \"X\"])\n",
    "    \n",
    "    # Save the pixel coordinates as a CSV file\n",
    "    df_coordinates.to_csv(output_coordinates_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your input and output paths\n",
    "    directory_mask = '...'\n",
    "    input_image_path = directory_mask + \"MAX_LDs.tif\"\n",
    "    output_mask_path = directory_mask +\"mask.png\"\n",
    "    output_isolated_path = directory_mask +\"isolated_puncta.png\"\n",
    "    output_expanded_path = directory_mask +\"expanded_puncta.png\"\n",
    "    output_coordinates_path = directory_mask +\"coordinates.csv\"\n",
    "\n",
    "    # Set the threshold value (you may need to adjust this)\n",
    "    threshold_value = threshold_value\n",
    "    \n",
    "    # Call the function to isolate puncta and collect coordinates\n",
    "    isolate_puncta(input_image_path, output_mask_path, output_isolated_path, output_coordinates_path, threshold_value)\n",
    "    mask_coordinates = pd.read_csv(output_coordinates_path, low_memory=False)\n",
    "    \n",
    "    inside = pd.DataFrame()\n",
    "    for key,grp in mask_coordinates.groupby('X'):\n",
    "        coord = coor[((coor['Y']//1).isin(grp.Y)) & ((coor['X']//1)==key) ]\n",
    "        inside = pd.concat([inside, coord])\n",
    "    \n",
    "        \n",
    "    outside = pd.concat([coor,inside]).drop_duplicates(keep=False)\n",
    "    \n",
    "    inside.X = inside.X/20\n",
    "    inside.Y = inside.Y/20\n",
    "    outside.X = outside.X/20\n",
    "    outside.Y = outside.Y/20\n",
    "    cmap_k = LinearSegmentedColormap.from_list('mycmap', ['white', 'black'])\n",
    "\n",
    "\n",
    "    \n",
    "inside['Loc'] = 'inside'\n",
    "outside['Loc'] = 'outside'\n",
    "\n",
    "MIN_track_info = pd.concat([outside, inside], ignore_index=True)\n",
    "\n",
    "plt.imshow(scaled, cmap=cmap3, extent=[0,Lengths[0],Lengths[1],0])\n",
    "sns.scatterplot(data= MIN_track_info, x = 'X', y = 'Y', hue = 'Loc', s = 0.05, alpha = 0.7, \n",
    "                 legend = True, palette = 'magma',  linewidth=0)\n",
    "plt.title('Threshold value: ' + str(threshold_value))\n",
    "\n",
    "\n",
    "plt.xlabel('X (µm)')\n",
    "plt.xlabel('Y (µm)')\n",
    "plt.xlim(0,Lengths[0])\n",
    "plt.ylim(Lengths[1], 0)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------MSD analysis for rach single molecule track--------------\n",
    "\n",
    "msd_info = pd.DataFrame()\n",
    "\n",
    "\n",
    "for track_id, group in MIN_track_info.groupby(['filename','track_id', 'Loc']):\n",
    "    \n",
    "    n = len(group)\n",
    "    msd = np.zeros(n)\n",
    "    lag = np.zeros(n)\n",
    "    tr = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        msd[i] = ((group.X.diff(periods=i)**2) + (group.X.diff(periods=i)**2)).mean()\n",
    "        lag[i] = i*group.time_int.median()\n",
    "\n",
    "\n",
    "    msdd = pd.DataFrame({'track_id':track_id[1], 'msd': msd, 'lag_time':lag})\n",
    "    msdd['loc'] = track_id[2]\n",
    "    msdd['filename']=track_id[0]\n",
    "    \n",
    "    msd_info = pd.concat([msd_info, msdd])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f57be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot MSD curves\n",
    "sns.lineplot(x=msd_info['lag_time'], y=msd_info['msd'], hue = msd_info['loc'], palette = 'magma')\n",
    "plt.xlim(0,0.5)\n",
    "plt.ylim(0,0.5)\n",
    "plt.xlabel('T (sec)')\n",
    "plt.ylabel('MSD (µm^2/s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------anomalous diffusion analysis--------------\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "D_alpha = pd.DataFrame()\n",
    "\n",
    "def power_law(t, D, alpha):\n",
    "    return 4* D * t**alpha\n",
    "\n",
    "\n",
    "alpha_cal = msd_info.dropna()\n",
    "for key,grp in alpha_cal.groupby(['filename','track_id', 'loc']):\n",
    "    if len(grp)> 3:\n",
    "        time = np.array(grp.lag_time)  # time data\n",
    "        \n",
    "        msd = np.array(grp.msd)  # MSD data\n",
    "    \n",
    "    \n",
    "    \n",
    "    popt, pcov = curve_fit(power_law, time, msd, maxfev=25000)\n",
    "    D, alpha = popt\n",
    "\n",
    "    values = pd.DataFrame({'filename': key[0], 'track_id': key[1], 'D': D, 'alpha':alpha, 'Loc':key[2] }, columns=['filename','track_id', 'D', 'alpha', 'Loc'], index=[0])\n",
    "    D_alpha = pd.concat([D_alpha, values])\n",
    "    \n",
    "#plot alpha values\n",
    "param = 'alpha'\n",
    "sns.histplot(data = data, x = param, hue = 'Loc', bins=50, element=\"step\", palette = 'magma',\n",
    "             stat = 'density', common_norm=False, fill = True, kde = True, log_scale = False)\n",
    "\n",
    "\n",
    "#statistics\n",
    "mann_whit = stats.mannwhitneyu(data[data['Loc']=='inside'][param], data[data['Loc']=='outside'][param], nan_policy='omit')\n",
    "plt.title('ER_mean: ' + str(data[data['Loc']=='outside'][param].mean()) + '\\nLD_mean: ' + \n",
    "         str(data[data['Loc']=='inside'][param].mean()) + '\\nER_median: ' + str(D_alpha[D_alpha['Loc']=='outside'][param].median()) + '\\nLD_median: ' + \n",
    "         str(data[data['Loc']=='inside'][param].median()) + '\\np: ' + str(mann_whit.pvalue))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e455116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------apparent diffusion coefficient calculation-------------\n",
    "\n",
    "def row_differences(group):\n",
    "    # Compute differences within each group\n",
    "    group['distance_sq'] = group['X'].diff(periods=period)**2 + group['Y'].diff(periods=period)**2\n",
    "    group['time_int'] = group['time'].diff(periods=period)\n",
    "    return group\n",
    "\n",
    "\n",
    "MIN_track_info = MIN_track_info.sort_values(by=['track_id', 'time'])\n",
    "MIN_track_info = MIN_track_info.groupby('track_id').apply(row_differences).drop(columns=['track_id']).reset_index()\n",
    "\n",
    "MIN_track_info = MIN_track_info.groupby('track_id').filter(lambda x: x['time'].count() > 570).drop(columns=['level_1']) #longer than 50ms\n",
    "MIN_track_info = MIN_track_info[(MIN_track_info['X']>=0) & (MIN_track_info['Y']>=0)] # remove any negative coordinates\n",
    "\n",
    "\n",
    "in_D = (MIN_track_info[MIN_track_info['Loc'] == 'inside'].groupby(['filename', 'track_id']).distance_sq.mean().reset_index())\n",
    "out_D = (MIN_track_info[MIN_track_info['Loc'] == 'outside'].groupby(['filename', 'track_id']).distance_sq.mean().reset_index())\n",
    "\n",
    "in_D['time_int'] = (MIN_track_info[MIN_track_info['Loc'] == 'inside'].groupby(['filename', 'track_id']).time_int.median().reset_index().drop(columns=['filename', 'track_id']))\n",
    "in_D['D'] = in_D.distance_sq/(in_D.time_int*4) #4Dt\n",
    "\n",
    "out_D['time_int'] = (MIN_track_info[MIN_track_info['Loc'] == 'outside'].groupby(['filename', 'track_id']).time_int.median().reset_index().drop(columns=['filename', 'track_id']))\n",
    "out_D['D'] = out_D.distance_sq/(out_D.time_int*4) #4Dt\n",
    "\n",
    "in_D['Loc'] = 'inside'\n",
    "out_D['Loc']='outside'\n",
    "\n",
    "D_values = pd.concat([in_D, out_D])\n",
    "\n",
    "#filter out the Dapp values bigger than 10µm^2/s\n",
    "D_values = D_values[D_values.D<10]\n",
    "\n",
    "#plot Dapp values\n",
    "sns.histplot(data = D_values, x = 'D', hue = 'Loc', palette = 'magma_r', bins = 50, kde = False, element=\"step\", stat = 'density', common_norm=False)\n",
    "\n",
    "#statistical tests\n",
    "mann_whit = stats.mannwhitneyu(in_D['D'], out_D['D'], nan_policy='omit')\n",
    "t_test = stats.ttest_ind(in_D['D'], out_D['D'], nan_policy='omit')\n",
    "\n",
    "plt.title('ER_D mean: ' + str(D_values[D_values['Loc']=='outside'].D.mean()) + '\\nLD_D mean: ' + str(D_values[D_values['Loc']=='inside'].D.mean()) +\n",
    "         '\\nER_D median: ' + str(D_values[D_values['Loc']=='outside'].D.median()) + '\\nLD_D median: ' + str(D_values[D_values['Loc']=='inside'].D.median()) + \n",
    "         '\\np: ' + str(mann_whit.pvalue))\n",
    "\n",
    "plt.xlim(0,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59bb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sampling rate\n",
    "\n",
    "sns.histplot(MIN_track_info.dropna().time_int, bins = 500, color = 'grey')\n",
    "plt.xlim(0,0.0008)\n",
    "plt.title('median: ' + str(min_total.dropna().time_int.median()) + '\\nmean: ' + str(min_total.dropna().time_int.mean()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc504b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4baff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
